{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm Used: Support Vector Machine\n",
    "\n",
    "upport Vector Machines (SVM) are well-suited for text classification tasks like spam detection because they handle high-dimensional and sparse data (e.g., TF-IDF vectors) effectively. SVM works by finding the optimal hyperplane that maximally separates different classes (spam vs. ham) with the largest margin. This makes it robust to overfitting, especially in small to medium-sized datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.33\n",
      "'Scientists invent teleportation technology, changing travel forever!' → Fake News\n",
      "'World Health Organization announces breakthrough in malaria vaccine.' → Real News\n",
      "'Shocking discovery: Atlantis city found under the ocean!' → Fake News\n",
      "'New smartphone released with groundbreaking AI features.' → Real News\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries (if not installed)\n",
    "# !pip install scikit-learn pandas numpy nltk\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# 1. Create a Fake News dataset\n",
    "data = {\n",
    "    \"text\": [\n",
    "        \"Breaking: Scientists discover a cure for COVID-19!\",  # Fake\n",
    "        \"NASA confirms water on the moon, groundbreaking discovery!\",  # Real\n",
    "        \"Experts warn of stock market collapse due to secret government policies.\",  # Fake\n",
    "        \"Government announces new tax relief for small businesses.\",  # Real\n",
    "        \"Shocking: Aliens found living in Area 51!\",  # Fake\n",
    "        \"New study finds link between exercise and improved mental health.\",  # Real\n",
    "        \"Politician caught hiding millions in offshore accounts.\",  # Fake\n",
    "        \"Medical researchers develop breakthrough cancer treatment.\",  # Real\n",
    "        \"Secret messages found in ancient pyramids predict end of the world!\",  # Fake\n",
    "        \"Tech company launches revolutionary AI that changes programming forever.\",  # Real\n",
    "    ],\n",
    "    \"label\": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]  # 1 = Fake, 0 = Real\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. Preprocess the text (lowercase, remove special characters, stopwords)\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(preprocess)\n",
    "\n",
    "# 3. Convert text into numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['clean_text'])\n",
    "y = np.array(df['label'])\n",
    "\n",
    "# 4. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 5. Train an SVM classifier\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6. Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# 7. Test with new headlines\n",
    "new_headlines = [\n",
    "    \"Scientists invent teleportation technology, changing travel forever!\",\n",
    "    \"World Health Organization announces breakthrough in malaria vaccine.\",\n",
    "    \"Shocking discovery: Atlantis city found under the ocean!\",\n",
    "    \"New smartphone released with groundbreaking AI features.\"\n",
    "]\n",
    "\n",
    "new_headlines_clean = [preprocess(news) for news in new_headlines]\n",
    "new_features = vectorizer.transform(new_headlines_clean)\n",
    "predictions = model.predict(new_features)\n",
    "\n",
    "# Print Predictions\n",
    "for headline, pred in zip(new_headlines, predictions):\n",
    "    category = \"Fake News\" if pred == 1 else \"Real News\"\n",
    "    print(f\"'{headline}' → {category}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
